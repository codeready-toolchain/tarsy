{
  "conversation": [
    {
      "content": "## General SRE Agent Instructions\n\nYou are an expert Site Reliability Engineer (SRE) with deep knowledge of:\n- Kubernetes and container orchestration\n- Cloud infrastructure and services\n- Incident response and troubleshooting\n- System monitoring and alerting\n- GitOps and deployment practices\n\nAnalyze alerts thoroughly and provide actionable insights based on:\n1. Alert information and context\n2. Associated runbook procedures\n3. Real-time system data from available tools\n\nAlways be specific, reference actual data, and provide clear next steps.\nFocus on root cause analysis and sustainable solutions.\n\n## Agent-Specific Instructions\n\nYou are DataCollector, gathering system metrics and pod status.\n\nFocus on investigation and providing recommendations for human operators to execute.",
      "role": "system"
    },
    {
      "content": "## Alert Details\n\n### Alert Metadata\n**Alert Type:** test-alert\n\n### Alert Data\n\u003c!-- ALERT_DATA_START --\u003e\nPod OOMKilled\n\u003c!-- ALERT_DATA_END --\u003e\n\n## Runbook Content\n````markdown\n\u003c!-- RUNBOOK START --\u003e\n# Generic Troubleshooting Guide\n\n## Investigation Steps\n\n1. **Analyze the alert** - Review alert data and identify affected system/service\n2. **Gather context** - Use tools to check current state and recent changes\n3. **Identify root cause** - Investigate potential causes based on alert type\n4. **Assess impact** - Determine scope and severity\n5. **Recommend actions** - Suggest safe investigation or remediation steps\n\n## Guidelines\n\n- Verify information before suggesting changes\n- Consider dependencies and potential side effects\n- Document findings and actions taken\n- Focus on understanding the problem before proposing solutions\n- When in doubt, gather more information rather than making assumptions\n\n## Common Investigation Patterns\n\n### For Performance Issues\n- Check resource utilization (CPU, memory, disk, network)\n- Review recent deployments or configuration changes\n- Analyze metrics and logs for anomalies\n- Identify bottlenecks in the request path\n\n### For Availability Issues\n- Verify service health and readiness\n- Check for recent restarts or crashes\n- Review dependencies and upstream services\n- Examine load balancer and routing configuration\n\n### For Error Rate Spikes\n- Analyze error messages and stack traces\n- Correlate with recent deployments\n- Check for external service failures\n- Review input validation and edge cases\n\n\u003c!-- RUNBOOK END --\u003e\n````\n\n## Previous Stage Data\nNo previous stage data is available for this alert. This is the first stage of analysis.\n\n## Your Task\nUse the available tools to investigate this alert and provide:\n1. Root cause analysis\n2. Current system state assessment\n3. Specific remediation steps for human operators\n4. Prevention recommendations\n\nBe thorough in your investigation before providing the final answer.",
      "role": "user"
    },
    {
      "content": "I'll look up the nodes and pods.",
      "role": "assistant",
      "tool_calls": [
        {
          "arguments": "{}",
          "id": "call-1",
          "name": "test-mcp__get_nodes"
        },
        {
          "arguments": "{\"namespace\":\"default\"}",
          "id": "call-2",
          "name": "test-mcp__get_pods"
        }
      ]
    }
  ],
  "created_at": "{TIMESTAMP}",
  "duration_ms": {DURATION_MS},
  "id": "{INTERACTION_ID_1}",
  "input_tokens": 100,
  "interaction_type": "iteration",
  "llm_request": {
    "iteration": 1,
    "messages_count": 2
  },
  "llm_response": {
    "text_length": 32,
    "tool_calls_count": 2
  },
  "model_name": "test-model",
  "output_tokens": 30,
  "thinking_content": "Let me check the cluster nodes and pod status.",
  "total_tokens": 130
}
