# TARSy Environment Variables
# Copy this file to .env and customize with your actual values
#
# cp .env.example .env
#
# IMPORTANT: Never commit .env file to git (it contains secrets)

# =============================================================================
# LLM API KEYS
# =============================================================================

# Google / Gemini API Key
# Get from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your-google-api-key-here

# OpenAI API Key
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# Anthropic API Key
# Get from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# X.AI API Key
# Get from: https://x.ai/api
XAI_API_KEY=your-xai-api-key-here

# =============================================================================
# GOOGLE CLOUD / VERTEX AI (Optional)
# =============================================================================

# GCP Project ID for Vertex AI
GOOGLE_CLOUD_PROJECT=your-gcp-project-id

# GCP Location for Vertex AI (e.g., us-central1, europe-west4)
GOOGLE_CLOUD_LOCATION=us-central1

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# PostgreSQL Connection Settings

# Local Development (host-based)
DB_HOST=localhost
DB_PORT=5432
DB_USER=tarsy
DB_PASSWORD=tarsy_dev_password
DB_NAME=tarsy
DB_SSLMODE=disable

# Podman/Docker Deployment (use service name)
# DB_HOST=postgres
# DB_PORT=5432
# DB_USER=tarsy
# DB_PASSWORD=tarsy_secure_password
# DB_NAME=tarsy
# DB_SSLMODE=require

# Kubernetes/OpenShift Deployment (use service FQDN)
# DB_HOST=postgres.tarsy.svc.cluster.local
# DB_PORT=5432
# DB_USER=tarsy
# DB_PASSWORD=${DB_PASSWORD_FROM_SECRET}
# DB_NAME=tarsy
# DB_SSLMODE=require

# =============================================================================
# SERVICE CONFIGURATION
# =============================================================================

# TARSy HTTP Server Port
HTTP_PORT=8080

# Python LLM Service gRPC Address
GRPC_ADDR=localhost:50051

# Gin Mode: "debug" | "release"
GIN_MODE=debug

# Configuration Directory (optional, defaults to ./deploy/config)
CONFIG_DIR=./deploy/config

# =============================================================================
# KUBERNETES / MCP SERVER CONFIGURATION
# =============================================================================

# Kubeconfig Path for Kubernetes MCP Server
KUBECONFIG=/home/user/.kube/config

# Multi-cluster setup: comma-separated contexts
# KUBECONFIG=/home/user/.kube/config-prod,/home/user/.kube/config-staging

# =============================================================================
# MCP SERVER ENDPOINTS (Optional)
# =============================================================================

# ArgoCD Server
ARGOCD_SERVER=argocd.example.com
ARGOCD_TOKEN=your-argocd-token

# Custom Monitoring MCP Server
MONITORING_MCP_URL=http://monitoring-mcp.example.com/mcp
MONITORING_TOKEN=your-monitoring-token

# =============================================================================
# OAUTH2 AUTHENTICATION (Optional)
# =============================================================================

# OAuth2 Proxy Configuration
OAUTH2_CLIENT_ID=your-oauth2-client-id
OAUTH2_CLIENT_SECRET=your-oauth2-client-secret
OAUTH2_COOKIE_SECRET=your-cookie-secret-32-chars-min

# GitHub OAuth (if using GitHub as provider)
GITHUB_ORG=your-github-org
GITHUB_TEAM=your-github-team

# =============================================================================
# SLACK NOTIFICATIONS (Optional - Phase 6)
# =============================================================================

# Slack Bot Token
# SLACK_BOT_TOKEN=xoxb-your-slack-bot-token

# Slack Channel for Notifications
# SLACK_CHANNEL=#tarsy-alerts

# =============================================================================
# ADVANCED CONFIGURATION (Optional)
# =============================================================================

# Override default LLM rate limits (requests per minute)
# LLM_RATE_LIMIT=60

# Override default max iterations
# MAX_ITERATIONS=25

# Override default iteration strategy
# ITERATION_STRATEGY=react

# =============================================================================
# DEPLOYMENT ENVIRONMENT EXAMPLES
# =============================================================================

# EXAMPLE 1: Local Development on Host
# - Database: localhost:5432
# - Services: localhost (HTTP/gRPC)
# - Kubeconfig: User's local kubeconfig

# EXAMPLE 2: Podman-Compose Deployment
# - Database: postgres (service name)
# - Services: tarsy-backend, tarsy-llm (service names)
# - Kubeconfig: Mounted from host

# EXAMPLE 3: Kubernetes/OpenShift Deployment
# - Database: postgres.tarsy.svc.cluster.local
# - Services: tarsy-backend.tarsy.svc.cluster.local
# - Kubeconfig: Mounted from ConfigMap/Secret
# - Secrets: Loaded from Kubernetes Secrets

# =============================================================================
# NOTES
# =============================================================================

# 1. Required Variables (minimum to run TARSy):
#    - GOOGLE_API_KEY (or another LLM provider key)
#    - DB_HOST, DB_PORT, DB_USER, DB_PASSWORD, DB_NAME
#    - KUBECONFIG (if using Kubernetes MCP server)

# 2. Optional Variables:
#    - Additional LLM provider keys (OpenAI, Anthropic, xAI)
#    - OAuth2 configuration (for authentication)
#    - Slack configuration (for notifications)
#    - Custom MCP server endpoints

# 3. Security Best Practices:
#    - Never commit .env file to version control
#    - Use strong passwords for database
#    - Rotate API keys regularly
#    - Use secrets management in production (K8s Secrets, Vault, etc.)

# 4. Environment-Specific Configuration:
#    - Use different .env files for different environments
#    - Or use environment-specific variable names
#    - Example: .env.local, .env.staging, .env.production
